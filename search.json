[
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "Bayesian Workflows - Advanced Seminar",
    "section": "",
    "text": "This is the webpage for “CS-E407520 Special Course in Machine Learning and Data Science: Bayesian Workflows” - a seminar on Bayesian workflows at Aalto University targeted at master students and doctoral researchers.\nIn this seminar, we dive into some of the essential steps of Bayesian modelling workflows and their application to practical analysis problems. We will be exploring how these Bayesian modelling workflows can be applied to a range of research questions, as well as common issues and problems that you might encounter. Students are strongly encouraged to bring their own analysis/modelling problem to apply each step of the workflow.\nYou will become familiar with available software tools that can support different aspects of modelling like prior sensitivity checks, choosing regularising priors, or using model comparison and model averaging techniques. You will gain hands-on experience working with your own modelling problem.\n\nPrerequisites\nSuccessful completion of CS-E5710 Bayesian Data Analysis or equivalent competence/experience with Bayesian data analysis.\nThe number of participants is limited to 30.\n\n\nAssessment\nYou will be assessed on your understanding of each of the workflow steps, the role they play in the Bayesian workflow, and how to apply them to real-world data.\n\n5 ECTS\nPass/Fail\nworkflow diary"
  },
  {
    "objectID": "materials.html",
    "href": "materials.html",
    "title": "Course Schedule and Content 2024",
    "section": "",
    "text": "Schedule Overview\nThe course is taught in period V (22 April – 3 June 2024) on Mondays from 14:15-16:00 in R030/A133 T5.\n\n\n\n\nSeminar Slides\nDate\n\n\n\n\nSession 1\nSlides\n22 April 2024\n\n\nSession 2\nSlides\n29 April 2024\n\n\nSession 3\nSlides\n06 May 2024\n\n\nSession 4\nSlides\n13 May 2024\n\n\nSession 5\nSlides\n20 May 2024\n\n\nSession 6\nSlides\n27 May 2024\n\n\nSession 7\nSlides\n3 June 2024\n\n\n\n\n\nSchedule Detail\n\nSession 1: Introduction to Bayesian Workflows\n\nLearning Outcomes for the Session\n\nUnderstanding of why data analysis / statistical / Bayesian Workflows are needed (i.e., current problems)\nBasic understanding of how Bayesian Workflows aim to solve problems\nBasic understanding of steps in workflow\n\n\n\nWhat the Session will Cover\n\nPracticalities of course\n\nDetails of the grading/assessment\nTiming/schedules\nWhere to find more information and support\n\nRelationship to prior BDA project tasks\n\nConcepts/tasks from BDA which will be relevant\n\nPossible datasets and modelling problems\n\nFor students without their own\n\nExploratory data analysis in Bayesian Workflow\n\n\n\nRecommended Reading Before Session\n\nBayesian Workflow (Gelman, et al., 2020)\n\nhttps://arxiv.org/abs/2011.01808\n\n\n\n\n\nSession 2: Choosing an Initial Model\n\nLearning Outcomes for the Session\n\nHow to specify a research question that can be answered with a statistical model\nAwareness of tools and methods to aid in exploring data and formulating question\nAwareness of common/standard modelling approaches for different questions\nStudents should have decided on their research question and at least 1 initial model\n\n\n\nWhat the Session will Cover\n\nUsing exploratory data analysis to support the choice of initial models\nCommon models and modelling approaches for common research questions\n\ne.g., observational, randomised study, purely exploratory, based on theory\n\nLiterature and best-practices can also help with model development\n\nUsing either an example or a student’s dataset/problem as an example\n\n\n\n\nRecommended Reading Before Session\n\nIterative Model Building (Aki Vehtari)\n\nhttps://www.youtube.com/watch?v=ppKpwtGy8KQ\n\n\n\n\n\nSession 3: Prior Choices\n\nLearning Outcomes for the Session\n\nDevelop awareness of impact of mis-specified priors\nUnderstanding of approaches for specifying prior (i.e., prior elicitation)\nUnderstanding of tools/methods for diagnosing prior sensitivity\n\n\n\nWhat the Session will Cover\n\nHow to turn assumptions/knowledge into prior\n\nGenerative priors, penalised complexity, etc.\nConnection to model expansion/choice/selection goals\nBrief coverage of different topics for prior choice\n\nHow to assess prior choice\n\nIf the type of prior / prior properties do not align, etc.\nPrior predictive checks\n\nHow to revise/modify a prior (if needed)\n\n\n\nRecommended Reading Before Session\n\n\n\nSession 4: Model Checking: Posterior Predictive Checks & Calibration\n\nLearning Outcomes for the Session\n\nUnderstanding role of predictive checks in model-checking\nUnderstanding of impact of different data types on approach (e.g., continuous vs discrete)\nFamiliarity with different graphical methods and tools for supporting checking\n\n\n\nWhat the Session will Cover\n\nDetecting, resolving, and reporting:\n\nPrior sensitivity\nPosterior predictive checks\nCalibration\n\n\n\n\nRecommended Reading Before Session\n\n\n\nSession 5: Extending Models and Model Selection\n\nLearning Outcomes for the Session\n\nUnderstanding of how to extend a model to better address a research question, and if it is even needed\nUnderstanding of how to select between different models, and whether this is necessary\nUnderstanding of how to combine multiple models for increased performance\n\n\n\nWhat the Session will Cover\n\nCommon methods for model expansion\n\nData-driven vs theory-driven\n\nCommon methods for model comparison, and interpreting the results of these\nAlternatives to model selection\n\ne.g., model averaging\n\n\n\n\nRecommended Reading Before Session\n\n\n\nSession 6: Interpreting and Presenting Model Results\n\nLearning Outcomes for the Session\n\nUsing model quantities and results to assess whether research question has been answered\n\nReflecting on how/if initial question has changed throughout workflow process\nReflection on possible alternative expansions for research questions/models\n\nPresenting model results accessibly\n\n\n\nWhat the Session will Cover\n\nHow to extract and prepare results\n\ne.g., using R packages such as tidybayes and marginaleffects\nFurther analysis of interesting effects (interactions, smooths, etc.)\n\nPrior sensitivity for final conclusions (quantities/choices not sensitive to priors)\nBrief introduction to alternative methods for constructing and reporting alternative models\n\ne.g., Multiverse analysis\n\n\n\n\nRecommended Reading Before Session\n\n\n\nSession 7: Summary & Presentations\n\nLearning Outcomes for the Session\n\nAwareness of how workflow will differ between research questions\nReflection of how workflow contributed to analysis process\nReflection on future iterations of model"
  },
  {
    "objectID": "template_workflow_diary.html",
    "href": "template_workflow_diary.html",
    "title": "Workflow Diary Example",
    "section": "",
    "text": "This workflow diary template will be used for you to record your experiences, attempts, and results while you apply the Bayesian workflow steps during each week of the seminar. Each section of the template corresponds to a step in the workflow that you will be applying, and specifies a suggested minimum ‘goal’ that you should aim to complete. How you decide to implement the workflow steps and achieve these goals is completely up to you.\nThere are no ‘wrong’ answers here, and you are not being graded on whether you implement the workflow steps ‘correctly’. This diary should be a record of your learning and experience with each workflow step, and will evolve as you learn more about the Bayesian workflow. If there are any issues or questions that you have, please record them in the diary so that we can discuss them during the in-person seminar sessions.\nRemember that you should be able to re-run, modify, or extend any of your code if requested during the interactive presentations.\n\n\n\nThere are a number of packages that you will need throughout this course. If you have any issues completing the setup steps below, please let us know.\n\n\nFor estimating Bayesian models in R, we recommend the cmdstanr package. You should be familiar with this if you have previously completed BDA. You can install cmdstanr, if it is not already installed, by running the following:\n\n# The 'cmdstanr' package is not available on CRAN, so you will need to install it from GitHub:\nif (!requireNamespace(\"remotes\", quietly = TRUE)) {\n  install.packages(\"remotes\")\n}\nif (!requireNamespace(\"cmdstanr\", quietly = TRUE)) {\n  remotes::install_github(\"stan-dev/cmdstanr\")\n}\n\nThe cmdstanr package is simply a wrapper/interface for the CmdStan command-line interface to Stan, which also needs to be installed. You can run the following code to check whether CmdStan is installed and up-to-date, and install it if necessary:\n\ncurr_ver &lt;- cmdstanr::cmdstan_version(error_on_NA = FALSE)\nif (is.null(curr_ver) || curr_ver &lt; cmdstanr:::latest_released_version()) {\n  cmdstanr::check_cmdstan_toolchain(fix = TRUE)\n  cmdstanr::install_cmdstan()\n}\nrm(curr_ver)\n\nA more user-friendly interface to cmdstanr is the brms package, which provides a formula-based interface to specify Bayesian models. You can install brms by running:\n\nif (!requireNamespace(\"brms\", quietly = TRUE)) {\n  install.packages(\"brms\")\n}\n\n\n\n\nThere are also some packages that you are likely to find useful for post-processing and diagnosing your models. These include bayesplot, posterior, loo, and priorsense. The first three would have been installed with brms above, and you can install priorsense by running the following:\n\n# The 'priorsense' package is not available on CRAN\n# so you will need to install it from GitHub:\nif (!requireNamespace(\"priorsense\", quietly = TRUE)) {\n  remotes::install_github(\"n-kall/priorsense\")\n}"
  },
  {
    "objectID": "template_workflow_diary.html#getting-started",
    "href": "template_workflow_diary.html#getting-started",
    "title": "Workflow Diary Example",
    "section": "",
    "text": "This workflow diary template will be used for you to record your experiences, attempts, and results while you apply the Bayesian workflow steps during each week of the seminar. Each section of the template corresponds to a step in the workflow that you will be applying, and specifies a suggested minimum ‘goal’ that you should aim to complete. How you decide to implement the workflow steps and achieve these goals is completely up to you.\nThere are no ‘wrong’ answers here, and you are not being graded on whether you implement the workflow steps ‘correctly’. This diary should be a record of your learning and experience with each workflow step, and will evolve as you learn more about the Bayesian workflow. If there are any issues or questions that you have, please record them in the diary so that we can discuss them during the in-person seminar sessions.\nRemember that you should be able to re-run, modify, or extend any of your code if requested during the interactive presentations.\n\n\n\nThere are a number of packages that you will need throughout this course. If you have any issues completing the setup steps below, please let us know.\n\n\nFor estimating Bayesian models in R, we recommend the cmdstanr package. You should be familiar with this if you have previously completed BDA. You can install cmdstanr, if it is not already installed, by running the following:\n\n# The 'cmdstanr' package is not available on CRAN, so you will need to install it from GitHub:\nif (!requireNamespace(\"remotes\", quietly = TRUE)) {\n  install.packages(\"remotes\")\n}\nif (!requireNamespace(\"cmdstanr\", quietly = TRUE)) {\n  remotes::install_github(\"stan-dev/cmdstanr\")\n}\n\nThe cmdstanr package is simply a wrapper/interface for the CmdStan command-line interface to Stan, which also needs to be installed. You can run the following code to check whether CmdStan is installed and up-to-date, and install it if necessary:\n\ncurr_ver &lt;- cmdstanr::cmdstan_version(error_on_NA = FALSE)\nif (is.null(curr_ver) || curr_ver &lt; cmdstanr:::latest_released_version()) {\n  cmdstanr::check_cmdstan_toolchain(fix = TRUE)\n  cmdstanr::install_cmdstan()\n}\nrm(curr_ver)\n\nA more user-friendly interface to cmdstanr is the brms package, which provides a formula-based interface to specify Bayesian models. You can install brms by running:\n\nif (!requireNamespace(\"brms\", quietly = TRUE)) {\n  install.packages(\"brms\")\n}\n\n\n\n\nThere are also some packages that you are likely to find useful for post-processing and diagnosing your models. These include bayesplot, posterior, loo, and priorsense. The first three would have been installed with brms above, and you can install priorsense by running the following:\n\n# The 'priorsense' package is not available on CRAN\n# so you will need to install it from GitHub:\nif (!requireNamespace(\"priorsense\", quietly = TRUE)) {\n  remotes::install_github(\"n-kall/priorsense\")\n}"
  },
  {
    "objectID": "template_workflow_diary.html#bayesian-workflow",
    "href": "template_workflow_diary.html#bayesian-workflow",
    "title": "Workflow Diary Example",
    "section": "Bayesian Workflow",
    "text": "Bayesian Workflow\n\nLoading Data and Preprocessing\nUse this section of the diary for loading your dataset of choice and performing any necessary preprocessing. This could include cleaning the data, transforming variables, or creating new variables. Remember that you should be able to re-run or modify this code if needed during the interactive presentations.\n\n# Your code here\n\n\n\nWeek 1: Exploratory Data Analysis and Choosing a Research Question\n\nGoal\nAfter this week, you should have:\n\nSetting up your project, for example, using the provided templates\nFormulating a research question & finding a dataset\nVisualising and getting familiar with characteristics of your data (e.g., range, data types)\nAdding your first notes and visualisations to the workflow diary\nPicking an initial model & documenting your reasoning and the strategies you used to choose it\nObtaining posterior samples using your initial model with default priors\nDocumenting what you observe and any issues you encounter in the workflow diary\n\n\n\nCode and Results\n\n# Your code here\n\n\n\n\nWeek 2: Prior Choice\n\nGoal\nAfter this week, you should have:\n\nProposed priors for each parameter in your model, with justification\nPerformed a prior predictive check to ensure that your priors are reasonable\n\n\n\nCode and Results\n\n# Your code here\n\n\n\n\nWeek 3: Model Fitting and Checking\n\nGoal\nAfter this week, you should have:\n\nFitted your model with chosen priors to your data\nPerformed diagnostic checks for quality/stability of fitting\nPerformed prior sensitivity assessment\nPerformed predictive performance assessment\n\n\n\nCode and Results\n\n# Your code here\n\n\n\n\nWeek 4: Extending Models and Model Selection\n\nGoal\nAfter this week, you should have:\n\nDecided on whether a model expansion or selection approach is relevant for your research question, with justification\nProposed a second model (or an expansion to the first), building on the issues/diagnostics/concepts from previous weeks\n\n\n\nCode and Results\n\n# Your code here\n\n\n\n\nWeek 5: Interpreting and Presenting Model Results\n\nGoal\nAfter this week, you should have:\n\nPrepared a concise summary of your results and how they answer your research question\nPrepared a visualisation of your results that is suitable for presentation to a non-technical audience\n\n\n\nCode and Results\n\n# Your code here\n\n\n\n\nWeek 6: Final Notebook\n\nGoal\nAfter this week, you should have:\n\nPrepared a separate notebook summarising your analysis and results in the form of a case study\n\nBe sure to use the case studies provided in this course to guide you"
  },
  {
    "objectID": "datasets.html",
    "href": "datasets.html",
    "title": "Analysis Dataset Options",
    "section": "",
    "text": "If you do not have a dataset or research problem that you are bringing to the course, below are some options. If you have previously completed BDA, you can use your dataset/project - as long as you are meaningfully expanding on the analyses and research question.\n\nmetafor Analysis Examples\nThe website for the metafor R package provides a large list of datasets and references for meta-analyses: Analysis Examples\n\n\nmetadat R Package\nThe metadat package also provides a large range of meta-analysis datasets: metadat\n\n\n‘Awesome Public Datasets’ Repository\nThe ‘Awesome Public Datasets’ GitHub repository provides a large number of datasets from multiple fields and study types: Awesome Public Datasets\n\n\nMinimum Wage Study (Causal Inference)\nThis is a classic example from economics in which interest lies in the causal effect of unemployment benefits on employment: here a link to a vignette that that replicates the original paper’s analysis\n\n\nmedicaldata R Package\nThe medicaldata package provides several medical datasets: medicaldata"
  }
]